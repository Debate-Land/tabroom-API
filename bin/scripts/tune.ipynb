{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import json\n",
    "import openai\n",
    "\n",
    "openai.api_key = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "PROMPT = \"\"\"\n",
    "You are a coach for high school debate. You want to classify judge paradigms based on whether the judge is \"progressive\" or \"traditional\". Progressive judges will entertain progressive arugments, such as kritiks (K's) and Theory shells and things like using music in the debate round.\n",
    "If they do not have any restrictions on progressive arguments and are completely accepting, they should be rated a 5.\n",
    "If they will vote for progressive arguments, but have a few stipulations, they should be rated a 4.\n",
    "If they know what progressive arguments are and state they may vote on them, but it isn't their preference, they should be rated a 3.\n",
    "If progressive argumentation isn't mentioned in their paradigm, they should be given a 2 if they seem to be technical otherwise (for example, they talk about flowing, being a former coach or debater).\n",
    "If they have no technical experience, they should be given a 1.\n",
    "\n",
    "Most judges will be 1s and 2s.\n",
    "\n",
    "Rank the given paradigms from 1 to 5, with 1 being a very traditional judge (not receptive to progressive arguments) and 10 being a very progressive judge. Only give a number and nothing else.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "with open('paradigms.csv', 'r') as f:\n",
    "    table = csv.reader(f)\n",
    "    for row in table:\n",
    "        data.append({\"messages\": [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": PROMPT\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": f\"Classify the following paradigm:\\n{row[0]}\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"assistant\",\n",
    "                \"content\": f\"{row[2]}\"\n",
    "            }\n",
    "        ]})\n",
    "\n",
    "with open(\"parsed.jsonl\", \"w\") as f:\n",
    "    for entry in data:\n",
    "        json.dump(entry, f)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = openai.files.create(\n",
    "  file=open(\"parsed.jsonl\", \"rb\"),\n",
    "  purpose='fine-tune'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_ID = response.id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ftjob-kaYXXE4oxlmxnXzxWIUMTGsM\n"
     ]
    }
   ],
   "source": [
    "response = openai.fine_tuning.jobs.create(training_file=FILE_ID, model=\"gpt-3.5-turbo\")\n",
    "print(response.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema import HumanMessage, SystemMessage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL = \"ft:gpt-3.5-turbo-0613:debate-land::8OClXt5D\"\n",
    "chat = ChatOpenAI(model=MODEL, api_key=openai.api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "response = chat([\n",
    "    SystemMessage(content=PROMPT),\n",
    "    HumanMessage(content=f\"Classify the following:\\n\\nI am a flow judge\")\n",
    "])\n",
    "\n",
    "result = None\n",
    "\n",
    "try:\n",
    "    result = int(response.content)\n",
    "except Exception:\n",
    "    pass\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
